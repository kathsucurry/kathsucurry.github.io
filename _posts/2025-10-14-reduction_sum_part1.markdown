---
layout: post
title:  "Reduction (Sum): part 1"
date:   2025-10-14
categories: cuda
---

As part of the "Reduction (Sum)" series, this post outlines my process and approach to implementing and optimizing sum reduction kernels. I use Mark Harris's [*Optimizing Parallel Reduction in CUDA* deck](https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf) as a reference, with modifications based on the insights I've gained along the way. My approach can be summarized as follows.

1. **Implement the reduction kernel** and ensure that the output is correct using the verification process described in the [previous post]({% link _posts/2025-10-14-reduction_sum_part0.markdown %}).
2. **Profile the kernel** using [NVIDIA Nsight Compute](https://developer.nvidia.com/nsight-compute). I highly recommend you to watch [this kernel profiling lecture](https://www.youtube.com/watch?v=F_BazucyCMw&t=1s) hosted by GPU Mode if you are interested in using Nsight Compute.
3. **Inspect the PTX/SASS**, if necessary, to better understand the performance characteristics or identify optimization opportunities.


# Kernel 0: the original interleaved addressing

The figure below summarizes the kernel implementation.

![image Original interleaved addressing](/assets/images/2025-10-14-reduction_sum_part1/kernel0_interleaved_address.png)
<p style="text-align: center;"><i>The first interleaved addressing kernel by Mark Harris.</i></p>

And you can find the relevant code below. Note the identical and interchangeable definition of the terms *batch* and *block* in this post.

```c++
template <size_t NUM_THREADS>
__global__ void batched_original_interleaved_address_0(
    float* __restrict__ Y,
    float const* __restrict__ X,
    size_t num_elements_per_batch
) {
    size_t const block_idx{blockIdx.x};
    size_t const thread_idx{threadIdx.x};
    // Allocate the shared memory with length of the number of threads in the block/batch.
    __shared__ float shared_data[NUM_THREADS];

    // Shift the input accordingly to the batch index.
    X += block_idx * num_elements_per_batch;
    // Store a single element per thread in shared memory.
    shared_data[thread_idx] = X[thread_idx];
    __syncthreads();

    for (size_t stride = 1; stride < NUM_THREADS; stride *= 2) {
        if (thread_idx % (2 * stride) == 0)
            shared_data[thread_idx] += shared_data[thread_idx + stride];
        __syncthreads();
    }

    if (thread_idx == 0)
        Y[block_idx] = shared_data[0];
}
```

Recall from the previous post that my GPU (RTX 5070 Ti) peak bandwidth is 896 GB/s and there are `2048 * 1024 * 256` number of elements. Running the kernel 50 times repeatedly with different numbers of threads per block leads to the following performance table. 

| # Threads/block | Runtime (Âµs) | Mean Effective Bandwidth | % Peak Bandwidth |
|:---:|:---:|:---:|:---:|
| 128 | 5,017.23 | 431.366 | 48.14 |
| 256 | 5,098.87 | 423.229 | 47.23 |
| 512 | 5,652.35 | 380.67 | 42.48 |
| 1,024 | 10,193.5 | 210.878 | 23.53 |

We observe that using 128 threads yields the best performance among all the options. Increasing the number of threads to 256 slightly degrades performance; using 512 threads reduces it further, and with 1,024 threads, performance drops significantly--the achieved bandwidth is nearly half that of the 128-thread configuration.

*What explains the performance differences across thread configurations?*

Let's start with the 1,024-thread configuration. In the previous post, we briefly discussed how the resources required by each block can limit the number of blocks that can be scheduled in each multiprocessor. These resources include the number of threads, the number of registers, and the amount of shared memory required per block.

The maximum threads per multiprocessor on my GPU is 1,536 (equivalent to 48 warps), as reported by the `maxThreadsPerMultiProcessor` field from `cudaGetDeviceProperties`. With a block size of 1,024, the GPU can only place 1 block (i.e., 32 warps) per SM. This means that out of the 48 warps slots available on the SM, only 32 are active, resulting in a theoretical occupancy of `32 / 48 * 100% = 66.67%`. In contrast, the other thread configurations are able to achieve 100% theoretical occupancy.

As mentioned earlier, the number of registers and the amount of shared memory per block can also limit occupancy; however, this is not the case for any of the thread configurations used here for this particular kernel.

*What about the remaining thread configurations? Why does the 128-thread configuration perform the best?*

Looking at the profile generated by Nsight Compute, all three thread configurations exhibit thread divergence.

![image Thread Divergence](/assets/images/2025-10-14-reduction_sum_part1/kernel0_thread_divergence.png)
<p style="text-align: center;"><i>One of the suggestions from Nsight Compute for the 128-thread configuration, which is to address the thread divergence issue.</i></p>

In our case, thread divergence occurs because the threads performing the sum operation in the `for` loop (i.e., the active threads whose indices satisfy the `if` condition) are scattered across multiple warps. In the 128-thread configuration, there are 64 active threads during the first iteration, but these threads are not grouped contiguously. The active threads consist of those with indices 0, 2, 4, 6, and so on. As a result, all 4 warps are partially active and must execute the loop body, leading to warp divergence. In ideal scenario, only 2 warps would be fully active and the remaining warps inactive, minimizing divergence. **Larger thread blocks can be more negatively affected by thread divergence since more warps increase the opportunity for divergence**, which may help explain why the runtime worsens as the number of threads per block increases from 128 to 256 and 512.

